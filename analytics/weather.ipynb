{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VA Project Weather in Australia - Team VA_AI_WIN\n",
    "\n",
    "This template just loads and uses a few of the discussed libraries. Please follow the instruction in Moodle and feel free to remove/update any cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disable some annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib_inline\n",
    "#plots the figures in place instead of a new window\n",
    "%matplotlib inline\n",
    "#matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "## Motivation and description\n",
    "We chose the rain in Australia dataset from [kaggle](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package) because we thought that it could be interesting to analyse a dataset with around 145k rows. It is also interesting that data from about 10 years of daily observations from different locations throughout Australia has been collected. The \"goal\" of this dataset is to find a model which is able to predict whether it will rain the next day or not. Besides several numerical attributes, also several categorical attributes are provided. The attributes of the used dataset are explained below.\n",
    "\n",
    "__Attributes__:\n",
    "\n",
    "- Date: The observation's date\n",
    "- Location: The location of the observation\n",
    "- MinTemp: The minimum temperature on that day (째C)\n",
    "- MaxTemp: The maximum temperature on that day (째C)\n",
    "- Rainfall: The rainfall amount measured in mm\n",
    "- Evaporation: The evaporation also measured in mm\n",
    "- Sunshine: The number of sunshine hours\n",
    "- WindGustDir: The strongest wind gust's direction\n",
    "- WindGustSpeed: The strongest wind gust's speed in km/h\n",
    "- WindDir9am: The wind's direction at 9 AM\n",
    "- WindDir3pm: The wind's direction at 3 PM\n",
    "- WindSpeed9am: The wind's speed (km/h) at 9 AM\n",
    "- WindSpeed3pm: The wind's speed (km/h) at 3 PM\n",
    "- Humidity9am: The humidity percentage at 9 AM\n",
    "- Humidity3pm: The humidity percentage at 3 PM\n",
    "- Pressure9am: The atmospheric pressure (hpa) at 9 AM\n",
    "- Pressure3pm: The atmospheric pressure (hpa) at 3 PM\n",
    "- Cloud9am: Fraction of obscured sky by clouds (in \"oktas\") at 9 AM\n",
    "- Cloud3pm: Same as above but at 3 PM\n",
    "- Temp9am: Temperature in 째C at 9 AM\n",
    "- Temp3pm: Temperature in 째C at 3 PM\n",
    "- RainToday: True, if it has been raining on that day, otherwise False\n",
    "- RainTomorrow: True, if it has been raining on the next day, otherwise False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First glimpse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a standard dataset of heterogenous data\n",
    "weather = pd.read_csv('data/weatherAUS.csv')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to a date type and create new columns\n",
    "weather['Date_converted'] = pd.to_datetime(weather['Date'], format='%Y-%m-%d')\n",
    "weather['Year'] = weather['Date_converted'].dt.year\n",
    "weather['Month'] = weather['Date_converted'].dt.month\n",
    "weather['Day'] = weather['Date_converted'].dt.day\n",
    "\n",
    "# Calculate percentage of null values per attribute\n",
    "missing_in_percentage = weather.isnull().sum() * 100 / len(weather)\n",
    "missing = pd.DataFrame({'col': weather.columns, 'missing_percent': missing_in_percentage})\n",
    "missing.sort_values('missing_percent', inplace=True, ascending=False)\n",
    "missing.head(8).style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"col\", y=\"missing_percent\", data=missing.head(8))\n",
    "ax.set_ylim((0, 100))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=300)\n",
    "ax.set_title('Percentage of missing values per DF column')\n",
    "ax.set_xlabel('DF columns')\n",
    "_ = ax.set_ylabel('Percentage of missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that for some columns nearly half of the values (40 - 48%) are missing (shown in the table as well as the plot above). Now we further investigate this issue by looking at the columns sunshine, evaporation, cloud3pm and cloud9am by grouping the percentage of missing values first by season, to look whether we can see a seasonal affect. We also group the percentage of missing values by location to see if we can spot a locational affect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of missing values per season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the dates to seasons and calculate for each season and attribute the percentage of missing values.\n",
    "seasons = {\n",
    "   1: 'Winter',\n",
    "   2: 'Spring',\n",
    "   3: 'Summer',\n",
    "   4: 'Autumn'\n",
    "}\n",
    "df_values_season = weather[['Year', 'Month', 'Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']].copy()\n",
    "\n",
    "df_values_season['Season'] = (df_values_season['Month'] % 12 + 3) // 3\n",
    "df_values_season['Season_name'] = df_values_season['Season'].map(seasons)\n",
    "\n",
    "df_season_count_null = df_values_season[['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']].isnull().groupby(df_values_season['Season_name']).sum()\n",
    "df_season_count_all = df_values_season[['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']].isnull().groupby(df_values_season['Season_name']).count()\n",
    "\n",
    "df_missing_values_percent = (df_season_count_null / df_season_count_all) * 100\n",
    "df_missing_values_percent['Season'] = df_missing_values_percent.index.tolist()\n",
    "df_missing_values_percent.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df_missing_values_percent.melt(id_vars=['Season'], var_name='Attribute', value_name='Percentage')\n",
    "ax = sns.catplot(data=df_melted, x='Attribute', y='Percentage', hue=\"Season\", kind=\"bar\")\n",
    "\n",
    "ax.set_ylabels(\"Percentage of missing values\")\n",
    "ax.set(ylim=(0,100))\n",
    "_ = ax.set(title=\"Percentage of missing values per attribute and season\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "It can be seen (table and plot) that there is not really a difference between the seasons. So a seasonal effect may be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of missing values per location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values_location = weather[['Location', 'Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']]\n",
    "df_values_location_count_null = weather[['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']].isnull().groupby(weather['Location']).sum()\n",
    "# fillna is needed in order to get the \n",
    "df_values_location_count_all = weather[['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']].isnull().groupby(weather['Location']).count()\n",
    "\n",
    "df_missing_values_percent = (df_values_location_count_null / df_values_location_count_all) * 100\n",
    "df_missing_values_percent['Location'] = df_missing_values_percent.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sunshine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sunshine_missing = df_missing_values_percent[['Location', 'Sunshine']]\n",
    "df_sunshine_missing = df_sunshine_missing.sort_values('Sunshine', ascending=False)\n",
    "# Number of locations\n",
    "len(df_sunshine_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sunshine_missing.head(30).style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,4))\n",
    "ax = sns.barplot(x='Location', y='Sunshine', data=df_sunshine_missing, color='b')\n",
    "ax.set_ylim((0, 100))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=300)\n",
    "ax.set_title('Percentage of missing sunshine values per location')\n",
    "ax.set_xlabel('Locations')\n",
    "_ = ax.set_ylabel('Percentage of missing sunshine values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "As it can be seen, for 19 of the 49 locations no values about the sunshine is tracked which explains the large amount of missing data for this attribute. The reason for this is, however, unknown.\n",
    "##### Evaporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaporation_missing = df_missing_values_percent[['Location', 'Evaporation']]\n",
    "df_evaporation_missing = df_evaporation_missing.sort_values('Evaporation', ascending=False)\n",
    "df_evaporation_missing.head(30).style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,4))\n",
    "ax = sns.barplot(x='Location', y='Evaporation', data=df_evaporation_missing, color='b')\n",
    "ax.set_ylim((0, 100))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=300)\n",
    "ax.set_title('Percentage of missing evaporation values per location')\n",
    "ax.set_xlabel('Locations')\n",
    "_ = ax.set_ylabel('Percentage of missing evaporation values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "As already has been shown before the reason for the high amount of null values might be that for 16 locations no evaporations are collected.\n",
    "##### Cloud 3 PM and Cloud 9 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud3pm_missing = df_missing_values_percent[['Cloud3pm']]\n",
    "df_cloud3pm_missing = df_cloud3pm_missing.reset_index()\n",
    "df_cloud3pm_missing = df_cloud3pm_missing.sort_values(['Cloud3pm', 'Location'], ascending=(False, True))\n",
    "\n",
    "df_cloud9am = df_missing_values_percent[['Cloud9am']]\n",
    "df_cloud9am = df_cloud9am.reset_index()\n",
    "df_cloud9am = df_cloud9am.sort_values(by=['Cloud9am', 'Location'], ascending=(False, True))\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "ax = sns.barplot(x='Location', y='Cloud3pm', data=df_cloud3pm_missing, color='b')\n",
    "ax.set_ylim((0, 100))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=300)\n",
    "ax.set_title('Percentage of missing 3 PM cloud values per location')\n",
    "ax.set_xlabel('Locations')\n",
    "_ = ax.set_ylabel('Percentage of missing 3 PM cloud values')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "ax = sns.barplot(x='Location', y='Cloud9am', data=df_cloud9am, color='b')\n",
    "ax.set_ylim((0, 100))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=300)\n",
    "ax.set_title('Percentage of missing 9 AM cloud values per location')\n",
    "ax.set_xlabel('Locations')\n",
    "_ = ax.set_ylabel('Percentage of missing 9 AM cloud values')\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "For the clouds at 3 PM and 9 PM value, we can also see that for the exact 12 countries no values are provided. We can therefore assume that at these locations, the fraction of sky obscured by cloud is not measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['Year', 'Month', 'Day']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at some maybe interesting attributes and a comparison between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'x': ['MinTemp'] * len(weather.MinTemp) + ['Temp9am'] * len(weather.Temp9am) + ['Temp3pm'] * len(weather.Temp3pm) + ['MaxTemp'] * len(weather.MaxTemp), 'y': weather.MinTemp.append([weather.Temp9am, weather.Temp3pm, weather.MaxTemp])}\n",
    "tmp = pd.DataFrame(tmp)\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "g = sns.violinplot(data=tmp, x='x', y='y')\n",
    "plt.title('Temperature')\n",
    "plt.ylabel('temperature in 째C') #, rotation='horizontal')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "All measured temperatures are similar distributed. The absolute values of the 3 PM temperature and the maximum temperature are also very similar. It follows, that the maximum temperature of a day occures around 3 PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'x': ['WindSpeed9am'] * len(weather.WindSpeed9am) + ['WindSpeed3pm'] * len(weather.WindSpeed3pm) + ['WindGustSpeed'] * len(weather.WindGustSpeed), 'y': weather.WindSpeed9am.append([weather.WindSpeed3pm, weather.WindGustSpeed])}\n",
    "tmp = pd.DataFrame(tmp)\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "g = sns.boxplot(data=tmp, x='x', y='y')\n",
    "plt.title('Wind Speed')\n",
    "plt.ylabel('wind speed in km/h') #, rotation='horizontal')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "General the wind speed on afternoons is higher. This is probably due to the higher temperatures and the resulting higher pressure differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'x': ['Humidity9am'] * len(weather.Humidity9am) + ['Humidity3pm'] * len(weather.Humidity3pm), 'y': weather.Humidity9am.append(weather.Humidity3pm)}\n",
    "tmp = pd.DataFrame(tmp)\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "g = sns.violinplot(data=tmp, x='x', y='y')\n",
    "plt.title('Humidity')\n",
    "plt.ylabel('rel. Humidity in %') #, rotation='horizontal')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The relative humidity is droping during the day, due to the rising temperature and the resulting higher dew point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(16, 9), sharex='col')\n",
    "sns.boxplot(data=weather, x='Rainfall', ax=axs[0,0])\n",
    "sns.boxplot(data=weather, x='Rainfall', ax=axs[0,1])\n",
    "#axs[0,1].set_xlim((0, 10))\n",
    "\n",
    "#sns.kdeplot(data=weather, x='Rainfall', ax=axs[1,0], cut=0, bw_adjust=.100)\n",
    "#sns.kdeplot(data=weather, x='Rainfall', ax=axs[1,1], cut=0, bw_adjust=.100)\n",
    "sns.histplot(data=weather, x='Rainfall', kde=False, ax=axs[1,0], binwidth=.4)\n",
    "sns.histplot(data=weather, x='Rainfall', kde=False, ax=axs[1,1], binwidth=.4)\n",
    "axs[1,1].set_xlim((0, 10))\n",
    "\n",
    "axs[0,0].set_title('full scale')\n",
    "axs[0,1].set_title('zoomed scale')\n",
    "axs[0,0].set_xlabel('')\n",
    "axs[0,1].set_xlabel('')\n",
    "axs[1,0].set_xlabel('Rainfall in mm')\n",
    "axs[1,1].set_xlabel('Rainfall in mm')\n",
    "fig.suptitle('Rainfall', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tmp = (weather.RainToday[weather.RainToday == 'Yes'].groupby(weather.Location).count() / weather.Location.groupby(weather.Location).count()).sort_values()\n",
    "tmp = tmp.to_frame('rain propability').reset_index()\n",
    "plt.figure(figsize=(20,5))\n",
    "ax = sns.barplot(data=tmp, x='Location', y='rain propability', color='b')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=300)\n",
    "plt.title('Rain Propability per Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Most of the time it is not raining. We can see that the rain has a relatively high range (0 - 371) whereby most of the data is rather small in contrast to the range. An explanation would be, as already mentioned, that it does not really rain often and when it rains, it then does not really rain much which is clear if we look at at the zoomed in plots.\n",
    "\n",
    "We can also see that the rainfall propability varies for all locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations\n",
    "\n",
    "In this section, we will look at different correlations of numerical attributes. We will look at the statistics as well as on correlation heatmaps and scatter plot matrices with and without categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data set without N/A values\n",
    "weather_correlations = weather.drop(columns=['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am'])\n",
    "weather_correlations.dropna(inplace=True)\n",
    "\n",
    "weather_correlations_numerical = weather_correlations[['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot matrices\n",
    "\n",
    "First have a look at the correlations. For better readability, we also plotted the correlation coefficents as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = weather_correlations_numerical.corr()\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap \n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, square=True, linewidths=.5, cbar_kws={\"shrink\": .5, 'label': 'Correlation coefficient'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we decided to look at the SPLOM of different combinations of attributes. Based on the correlation coefficients above, we decided to look at some reasonable scatter plot matrices (SPLOMs).\n",
    "Mainly on different temperature related values since they highly significant correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot matrices without categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(weather_correlations_numerical[['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm']])\n",
    "grid.fig.subplots_adjust(top=0.9)\n",
    "_= grid.fig.suptitle('SPLOM of MinTemp, MaxTemp, Temp9am and Temp3pm')\n",
    "\n",
    "weather_correlations_numerical[['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "We can here clearly see that for every temperature combination, a positive correlation exists. However, this correlation is not so strong in every combination, e.g. if we look at the correlation between min and max temperature, we can obviously see that this positive correlated relationship is due to the reason that a maximum temperature is always higher than a min temperature. So a higher minimum temperature tends for higher maximum temperatures. The same for e.g. Temp9am and the minimum temperature. If the minimum temperature is low than the temperature at 9 AM is probably also low. This observations makes sense because 9 AM is before midday and therefore the temperature is still relatively low.\n",
    "\n",
    "We can also so see that for the temperature at 3 PM we are relatively close to the maximum temperature which makes sense because at 3 PM the temperature is normally relatively high compared to the whole day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(weather_correlations_numerical[['MinTemp', 'MaxTemp', 'Rainfall']])\n",
    "grid.fig.subplots_adjust(top=0.9)\n",
    "_ = grid.fig.suptitle('SPLOM of MinTemp, MaxTemp and Rainfall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "For the rainfall, we can see that the highest amount is around days where the minimum temperature is around 20 degrees and the maximum temperature is around 20 to 30 degrees. One logical explanation would be that when it is cold, there is no rain and hot days (temperature above ~35 degrees) there is also little rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(weather_correlations_numerical[['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm', 'Humidity9am', 'Humidity3pm']])\n",
    "grid.fig.subplots_adjust(top=0.9)\n",
    "_ = grid.fig.suptitle('SPLOM of MinTemp, MaxTemp, Temp9am, Temp3pm, Humidity9am and Humidity3pm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "For both humidity measures we might see a small negative correlation with different temperature measurements but in general it is rather a point cloud.\n",
    "\n",
    "If we look at the correlation between both humidity attributes we can see that they are slightly positive correlated but again, this is also rather a point cloud but the correlation coefficient is here at around 0.68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(weather_correlations_numerical[['WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm']])\n",
    "grid.fig.subplots_adjust(top=0.9)\n",
    "_ = grid.fig.suptitle('SPLOM of WindGustSpeed, WindSpeed9am and WindSpeed3pm')\n",
    "\n",
    "weather_correlations_numerical[['WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "We can see that there is a overall a positive correlation, although not very strong. We think that this is due to the fact that on generally windy days with higher max wind gust speed leads generally to higher wind speed at 3 PM and at 9 PM. But again, the data is rather a point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot matrices with categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the first scatter plot matrix and color the data points according to different categorical attributes and look wether or not we can see a pattern.\n",
    "\n",
    "We decided to only use the first SPLOM because it has the most correlated attributes with the highest correlation coefficient.\n",
    "\n",
    "For the categorical attributes we first use RainToday and then RainTomorrow because from our point of view, these two categorical attributes make much more sense than the\n",
    "other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(weather_correlations[['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm', 'RainToday']], hue='RainToday', plot_kws={'alpha': 0.1})\n",
    "grid.fig.subplots_adjust(top=0.9)\n",
    "_= grid.fig.suptitle('SPLOM of MinTemp, MaxTemp, Temp9am and Temp3pm with the categorical attribute RainToday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "Here we can see that the max temperature on rainy days is rather low when we look at the corresponding minimum temperature. We can also see that the range of max temperature for every minimum temperature is much larger on dry days than on rainy ones. This may be due to the fact that on exteme hot days there is little rain. It can also be seen that or rainy days this correlation looks very linear in contrast to dry days.\n",
    "\n",
    "We can also see that the minimum temperature correlates stronger with the temperature at 3 PM if we only look on rainy days. We can also see that, like with the maximum temperature, the relatively lower end of the temperature at 3 PM for every minimum temperature is marked as rainy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(weather_correlations[['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm', 'RainTomorrow']], hue='RainTomorrow', plot_kws={'alpha': 0.1})\n",
    "grid.fig.subplots_adjust(top=0.9)\n",
    "_= grid.fig.suptitle('SPLOM of MinTemp, MaxTemp, Temp9am and Temp3pm with the categorical attribute RainTomorrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "Here it also looks almost the same as above, but for the max temperature with the temperature at 3 PM plot, we can see that the rainy days are more scattered than above.\n",
    "\n",
    "At the temperature at 9 AM and 3 PM scatter plot, we can see that rainy tomorrow days are more aligned at the lower end of the correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather throughout the years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we take a look at the development of various weather-related factors over time. Because the data for years before 2009 and after 2016 is incomplete, only 2009 until the end of 2016 will be considered.\n",
    "And all locations with insufficient data will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relyears = weather[weather['Year'] > 2008]\n",
    "relyears = relyears[relyears['Year'] < 2017]\n",
    "\n",
    "tmp = pd.DataFrame(relyears.MaxTemp.groupby(relyears.Location).count())\n",
    "print(f'removing following locations: {tmp[tmp.MaxTemp < 2500].index.values.tolist()}')\n",
    "relyears = relyears[~relyears.Location.isin(tmp[tmp.MaxTemp < 2500].index.values.tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we inspect the temperature development over the whole country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtemps = relyears.groupby('Year')['MaxTemp'].mean()\n",
    "mintemps = relyears.groupby('Year')['MinTemp'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maxtemps)\n",
    "print(mintemps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "sns.lineplot(mintemps.index, mintemps, color='#1f77b4', label='MinTemp').set(title=\"Mean min. temperature over the years of all locations\")\n",
    "sns.regplot(mintemps.index, mintemps, scatter=False, color='darkblue', label='trend')\n",
    "plt.ylabel('MinTemp in 째C')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "sns.lineplot(maxtemps.index, maxtemps, color='red', label='MaxTemp').set(title=\"Mean max. temperature over the years of all locations\")\n",
    "sns.regplot(maxtemps.index, maxtemps, scatter=False, color='darkred', label='trend')\n",
    "plt.ylabel('MinTemp in 째C')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "sns.lineplot(maxtemps.index, maxtemps - mintemps, color='g', label='max - min').set(title=\"Difference between max. and min. temperatures\")\n",
    "plt.ylabel('difference in 째C')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "There are multiple things we can see here. First off, it appears that the year 2012 has been exceptionally cold. Furthermore, a weak correlation of mininum and maximum temperatures can be seen up until the year 2014. From 2013 onwards, the difference of mininum and maximum seems to become smaller, as minimum temperatures continue rising, but maximum temperatures do not. This could indicate that nights are getting warmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take a look at rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = relyears.groupby('Year')['Rainfall'].mean()\n",
    "print(rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "sns.lineplot(rain.index, rain, color='blue', label='rainfall')\n",
    "sns.regplot(rain.index, rain, scatter=False, color='lightblue', label='trend')\n",
    "plt.title(\"Mean millilitres of rainfall over the years of all locations\")\n",
    "plt.ylabel('Rainfall in mm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "If we take a look at the temperature graphs and compare them to this graph, we can see that for years which are in average \"colder\", an increase in mean rainfall has been recorded. Likewise, \"hotter\" years have been less rainy.  \n",
    "The trend points toward fewer rainfall in average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive part\n",
    "## Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "pca_weather = None\n",
    "detail = None\n",
    "weatherDR=weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "First we looked at different ways of reducing dimensions. Then we decided on using PCA, because it delivers good results regardless of the number of features.\n",
    "\n",
    "We decided to use only numeric features, because the common reduction algorithms are mostly optimized for numeric or categorical approaches not both. \n",
    "Other algorithms such as FAMD require their own libraries, which caused problems for us during installation.  Since we do not know the setups the tutors use, they could run into similar problems. Accordingly we decided against such an approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_PCA(column):\n",
    "    if len(column) < 3:\n",
    "        print(\"At least three collumns must be chossen\")\n",
    "        return\n",
    "    global pca_weather \n",
    "    pca_weather = None\n",
    "    l=list(column)\n",
    "    l.append('Location')\n",
    "    weatherDR_PCA = weatherDR[l]\n",
    "\n",
    "    weatherDR_PCA=weatherDR_PCA.dropna()\n",
    "\n",
    "    pca_weather=StandardScaler().fit_transform(weatherDR_PCA[list(column)])\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_weather = pca.fit_transform(pca_weather)\n",
    "    weatherDR_PCA[\"X\"]=pca_weather[:,0]\n",
    "    weatherDR_PCA[\"Y\"]=pca_weather[:,1]\n",
    "    pca_weather =  weatherDR_PCA\n",
    "    \n",
    "    if detail is not None:\n",
    "        detail.widget.children[1].options = column\n",
    "        detail.widget.children[4].options = column\n",
    "        detail.widget.children[1].value = column[0]\n",
    "        detail.widget.children[4].value = column[1]\n",
    "\n",
    "\n",
    "    print(\"Dataset is ready\")\n",
    "    print(\"Rows in the Dataset: \" +str(pca_weather.shape[0]))\n",
    "\n",
    "interact_manual(do_PCA,column=widgets.SelectMultiple(options=[\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"Evaporation\", \"Sunshine\", \"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"Cloud9am\", \"Cloud3pm\", \"Temp9am\", \"Temp3pm\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "For clustering, we wanted two algorithms we are familiar with, so a better interpretation of the results could be ensured. \n",
    "We also set a focus on offering a similar GUI for both algorithms to a potential user.\n",
    "We got to the K-Means relatively quickly and we found a suitable algorithm in agglomerative clustering. Unfortunately, it turned out that the agglomerative cluster in sk-learning is not deterministic, since no Seed can be used.\n",
    "\n",
    "However, this was not much of a problem, and we even took it for a chance. We had high hopes, the variance could lead to new findings. But it turned out, that the variance was too small to make a discernible difference.\n",
    "For the number of clusters, we went with our experience. Based on those, we chose parameters, which made sense and still had enough information content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(clusters):\n",
    "    return KMeans(n_clusters=clusters, random_state=42)\n",
    "\n",
    "def agg_clust(clusters):\n",
    "       return AgglomerativeClustering(n_clusters=clusters)\n",
    "\n",
    "def prep_interaction(algorithmn, clusters):\n",
    "    global pca_weather\n",
    "\n",
    "    if pca_weather is None:\n",
    "        print(\"Dataset not ready\")\n",
    "        return;\n",
    "\n",
    "    X=pca_weather[[\"X\", \"Y\"]].to_numpy()\n",
    "    if(algorithmn==\"K-Means\"):\n",
    "        model=k_means(clusters)\n",
    "    elif(algorithmn==\"Agg. CLustering\"):\n",
    "        model=agg_clust(clusters)\n",
    "    yhat = model.fit_predict(X)\n",
    "    pca_weather[\"Cluster\"]=yhat\n",
    "    cl = unique(yhat)\n",
    "    fig, ax = plt.subplots()\n",
    "    for cluster in cl:\n",
    "        row_ix = where(yhat == cluster)\n",
    "        ax.scatter(X[row_ix, 0], X[row_ix, 1], alpha=0.9, label=str(cluster+1), s=0.6)\n",
    "    global detail\n",
    "    if detail is not None:\n",
    "        detail.widget.children[0].max = clusters\n",
    "    ax.legend()\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\") \n",
    "    \n",
    "interact_manual(prep_interaction, algorithmn=[\"K-Means\", \"Agg. CLustering\"],  clusters=(2,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlook \n",
    "The overview is simply intended to give a quick overview of the values of the individual columns in the individual clusters.\n",
    "This section also provides distribution charts for every attribute and therefore, provide an overview of the distributions over the individual clusters.\n",
    "\n",
    "Information which can be used in the Detail View Examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_cluster():\n",
    "    cl=np.unique(pca_weather[['Cluster']].values)\n",
    "    for cluster in cl:\n",
    "        d=pca_weather[pca_weather['Cluster']==cluster]\n",
    "        d=d.drop([\"X\",\"Y\", \"Cluster\"], axis=1)\n",
    "        print(\"Cluster \"+str(cluster+1)+\":\")\n",
    "        display(d.describe().drop(\"count\", axis=0))\n",
    "    \n",
    "    for col in [\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"Evaporation\", \"Sunshine\", \"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"Cloud9am\", \"Cloud3pm\", \"Temp9am\", \"Temp3pm\"]:\n",
    "        if col in pca_weather.columns:\n",
    "            _, ax = plt.subplots(1, 3, figsize=(18, 6), gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
    "            \n",
    "            bx_plot = sns.boxplot(data=pca_weather, y=col, x='Cluster', ax=ax[0], palette='tab10')\n",
    "            sns.kdeplot(data=pca_weather, x=col, hue='Cluster', ax=ax[1], palette='tab10')\n",
    "            sns.violinplot(data=pca_weather, y=col, x='Cluster', ax=ax[2], palette='tab10')\n",
    "            \n",
    "            ax[0].set_title(f\"Boxplot of attribute '{col}'\")\n",
    "            ax[1].set_title(f\"Density plot of attribute '{col}'\")\n",
    "            ax[2].set_title(f\"Violin plot of attribute '{col}'\")\n",
    "\n",
    "\n",
    "overlook=interact_manual(overview_cluster)\n",
    "display(overlook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail\n",
    "Two things were important for the detailed view. First, we wanted a detailed view of each cluster. Second, we wanted to have a comparison between two columns. The reason we chose this approach was, that we believe a comparison of two columns still offers a clear result.\n",
    "\n",
    "The controls work like this:\n",
    "- In the cluster you select the cluster that you want to look at specifically.\n",
    "- With Column you select the Column that you specifically want to emphasize.\n",
    "- Range attribute: You can have the range you want specifically highlighted. [0.00, corresponds to the min value and 100 to the max value]\n",
    "- Finally, you can still determine how the two ranges are merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimRed=[\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"Evaporation\", \"Sunshine\", \"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"Cloud9am\", \"Cloud3pm\", \"Temp9am\", \"Temp3pm\"]\n",
    "slider1 = widgets.FloatRangeSlider(\n",
    "    value=[0.0, 100.0],\n",
    "    min=0.0,\n",
    "    max=100.0,\n",
    "    step=0.1,\n",
    "    description='Range Attribut 1:',\n",
    "    style = {'description_width': 'initial'})\n",
    "slider2 = widgets.FloatRangeSlider(\n",
    "    value=[0.0, 100.0],\n",
    "    min=0.0,\n",
    "    max=100.0,\n",
    "    step=0.1,\n",
    "    description='Range Attribut 2:',\n",
    "    style = {'description_width': 'initial'})\n",
    "\n",
    "def lookInto(cluster, collumn1,  range1, operation, collumn2,  range2):\n",
    "    global pca_weather\n",
    "    if  pca_weather is None:\n",
    "        print(\"CLustering not finished\")\n",
    "        return\n",
    "    if \"Cluster\" not in pca_weather.columns:\n",
    "        print(\"CLustering not finished\")\n",
    "        return\n",
    "    if(collumn1 != collumn2):\n",
    "        d=pca_weather[[collumn1, collumn2, \"X\", \"Y\", \"Cluster\", \"Location\"]]\n",
    "    else:\n",
    "        d=pca_weather[[collumn1, \"X\", \"Y\", \"Cluster\", \"Location\"]]\n",
    "\n",
    "    d=d[d[\"Cluster\"]==(cluster-1)]\n",
    "    c1=None\n",
    "    c2=None\n",
    "    if range1 != (0.00, 100):\n",
    "        c1=d[[collumn1]]\n",
    "        max=c1.max()[0]\n",
    "        min=c1.min()[0]\n",
    "        \n",
    "        prc=(c1.max()[0]-c1.min()[0]) /100\n",
    "        c1=np.logical_and(c1[collumn1] >= min+prc*range1[0], c1[collumn1] <= min+prc*range1[1])\n",
    "        \n",
    "    if range2 != (0.00, 100):\n",
    "        c2=d[[collumn2]]\n",
    "        max=c2.max()[0]\n",
    "        min=c2.min()[0]\n",
    "        \n",
    "        prc=(c2.max()[0]-c2.min()[0]) /100\n",
    "        c2=np.logical_and(c2[collumn2] >= min+prc*range2[0], c2[collumn2] <= min+prc*range1[1])\n",
    "            \n",
    "\n",
    "    if c1 is None and c2 is None:\n",
    "        fig, ax = plt.subplots(2, figsize=(20, 20))\n",
    "        ax[0].set_title(\"Cluster \"+str(cluster)+\": X vs Y\")\n",
    "        ax[0].scatter(d[\"X\"], d[\"Y\"], alpha=0.4, label=str(cluster), s=4.0)\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        \n",
    "        ax[1].set_title(\"Cluster \"+str(cluster)+\": \"+collumn1+\" vs \"+collumn2)\n",
    "        ax[1].scatter(d[collumn1], d[collumn2], alpha=0.4,  label=\"Cluster \"+str(cluster), s=4.0)\n",
    "        ax[1].legend()\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        \n",
    "        ax[0].legend()\n",
    "        ax[1].legend()\n",
    "\n",
    "\n",
    "        return \n",
    "        \n",
    "    else:\n",
    "        if(collumn1==collumn2):\n",
    "            fig, ax = plt.subplots(3, figsize=(25, 20), gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
    "        \n",
    "        else:\n",
    "            fig, ax = plt.subplots(4, figsize=(25, 20), gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
    "\n",
    "        if c1 is not None and c2 is not None:\n",
    "            if operation==\"AND\":\n",
    "                c=np.logical_and(c1,c2)\n",
    "            elif operation==\"OR\":\n",
    "                c=np.logical_or(c1,c2)\n",
    "            elif operation==\"XOR\":\n",
    "                c=np.logical_xor(c1,c2)\n",
    "        if c1 is None:\n",
    "            c=c2\n",
    "        if c2 is None:\n",
    "            c=c1\n",
    "\n",
    "        hit  = d[c]\n",
    "        miss = d[np.logical_not(c)]\n",
    "        \n",
    "        d['Category'] = [\"Hit\" if val else 'Miss' for val in c]\n",
    "\n",
    "        ax[0].set_title('Cluster '+str(cluster)+': Hit / Miss on X vs Y')\n",
    "\n",
    "        ax[0].scatter(hit[\"X\"], hit[\"Y\"], alpha=0.4,  label=\"HIT (\"+str((hit.shape[0])//((miss.shape[0]+hit.shape[0])//100))+\"%)\", s=4.0)\n",
    "        ax[0].scatter(miss[\"X\"], miss[\"Y\"], alpha=0.4, label=\"MISS(\"+str((miss.shape[0])//((miss.shape[0]+hit.shape[0])//100))+\"%)\", s=4.0)\n",
    "        ax[0].legend()\n",
    "        plt.setp(ax[0], ylabel= 'Y')\n",
    "        plt.setp(ax[0], xlabel= 'X')\n",
    "\n",
    "        ax[1].set_title('Cluster '+str(cluster)+': Hit / Miss on '+collumn1+' vs '+collumn2)\n",
    "        ax[1].scatter(hit[collumn1], hit[collumn2], alpha=0.6,  label=\"HIT (\"+str((hit.shape[0])//((miss.shape[0]+hit.shape[0])//100))+\"%)\", s=4.0)\n",
    "        ax[1].scatter(miss[collumn1], miss[collumn2], alpha=0.6, label=\"MISS(\"+str((miss.shape[0])//((miss.shape[0]+hit.shape[0])//100))+\"%)\", s=4.0)\n",
    "        ax[1].legend()\n",
    "        plt.setp(ax[1], ylabel= collumn1)\n",
    "        plt.setp(ax[1], xlabel= collumn2)\n",
    "\n",
    "        \n",
    "        x1 = list(hit[collumn1])\n",
    "        x2 = list(miss[collumn1])\n",
    "\n",
    "        names = ['Hit', 'Miss']\n",
    "        \n",
    "        sns.kdeplot(data=d, x=collumn1, hue=\"Category\", ax=ax[2])\n",
    "        ax[2].set_title(f\"Cluster {cluster}: Density plot of '{collumn1}'\")\n",
    "\n",
    "        x1 = list(hit[collumn2])\n",
    "        x2 = list(miss[collumn2])\n",
    "        if(collumn1!=collumn2):\n",
    "            sns.kdeplot(data=d, x=collumn2, hue=\"Category\", ax=ax[3])\n",
    "            ax[3].set_title(f\"Cluster {cluster}:Density plot of '{collumn2}'\");\n",
    "            \n",
    "            _ = plt.figure()\n",
    "            _ = sns.jointplot(data=d, x=collumn1, y=collumn2, hue=\"Category\", alpha=0.1)\n",
    " \n",
    "\n",
    "detail = interact_manual(lookInto,  cluster=(1,12), collumn1=dimRed,  operation=[\"AND\", \"OR\", \"XOR\"], range1=slider1, collumn2=dimRed,  range2=slider2)\n",
    "display(detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation__:\n",
    "\n",
    "For this interpretation we used the k-means algorithm with three clusters, since more clusters lead to harder interpretable results. Furthermore, we used all available columns for the dimension reduction procedure.\n",
    "\n",
    "We can see that the first cluster (cluster 0) rather contains \"colder\" temperatures (min, max, temperature at 9 AM and 3 PM) whereas the second cluster contains \"higher\" temperatures. Finally, the third cluster mostly contains temperatures which are in the middle. Furthermore, the first cluster rather contains higher pressure variables than the other ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This section briefly describes who we reached the requirements of this exercise. The first five points from the task description are obviously fulfilled, so we won't go into detail there.\n",
    "\n",
    "- First we checked about the high occurrence of null values for certain attributes where we found out that this values were not recorded at every location and therefore there were the high amount of null values.\n",
    "- We then found that the distribution of the rainfall amount is skewed, i.e. that on most days there is no rain or little rain, but the range is relatively high but with few high values.\n",
    "- We found out that the distribution of the max temperature and the temperature at 3 PM are very similar and therefore, the maximum temperature of a day occurs around 3 PM.\n",
    "- We also found out that the humidity is dropping during the day, due to rising temperature and the resulting higher dew point.\n",
    "- Wind speeds are generally higher in afternoons which might be due to higher temperatures and the resulting higher pressure differences.\n",
    "- We also found out that the min temperature positively correlates with the maximum temperature which might be because higher minimum temperatures lead to higher maximum temperatures. The same for the temperature at 9 AM and 3 PM.\n",
    "- We added the categorical attribute 'RainToday' and found out that the temperatures on rainy days are rather lower than on hot days, so for the minimum temperatures the corresponding max temperatures are rather low compared to the values on not raining days.\n",
    "- We also visualized the minimum and maximum temperatures as well as the rainfall throughout the years. Here we found out that the required data before 2009 and after 2016 is incomplete, so we only visualized this time frame.\n",
    "    - Here we found out that 2012 was exceptionally cold.\n",
    "    - From 2013 onwards, the difference between the average minimum and average maximum temperature is getting smaller which might lead to warmer nights since the average minimum temperature is rising.\n",
    "    - We found out that there is less rainfall on \"hotter\" years and more on \"colder\" year. The chart's trend also shows that the average rainfall per year is sinking.\n",
    "- For the interactive part we implemented the dimensionality reduction using PCA because it is fast and delivers good results regardless of the number of selected features but we only used numerical attributes since common reduction algorithms are optimized for such scenarios.\n",
    "- For the clustering part we implemented k-means and agglomerative clustering. Then the clusters can be investigated by looking at the attributes' distribution plots or using the second interactive part where different attributes and their correlation can be further investigated.\n",
    "- As mentioned before, we used the k-means with three clusters, since the interpretation for more clusters would be harder and not so obvious.\n",
    "    - We can see that the first cluster (cluster 0) rather contains \"colder\" temperatures (min, max, temperature at 9 AM and 3 PM) whereas the second cluster contains \"higher\" temperatures. Finally, the third cluster mostly contains temperatures which are in the middle. Furthermore, the first cluster rather contains higher pressure variables thant the other ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
